{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Intro to Text Analytics in Python</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of Musicians and their lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dataset of song lyrics from 4 different artists (Beatles, Metallica, Eminem, Bob Dylan)\n",
    "* use 2 methods to model pattern in the lyrics\n",
    "* plot some of those patterns\n",
    "\n",
    "### Motivating Assumption: similar songs to be close together in pattern and plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](tfidf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Help!</td>\n",
       "      <td>(When) When I was younger (When I was young) s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Ticket to Ride</td>\n",
       "      <td>I think I'm gonna be sad, I think it's today, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>A Hard Days Night</td>\n",
       "      <td>It's been a hard day's night, and I been worki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Cant Buy Me Love</td>\n",
       "      <td>Can't buy me love, love Can't buy me love I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Eleanor Rigby</td>\n",
       "      <td>Ah look at all the lonely people Ah look at al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>I Want to Hold Your Hand</td>\n",
       "      <td>Oh yeah, I'll tell you something I think you'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>She Loves You</td>\n",
       "      <td>She loves you, yeah, yeah, yeah She loves you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>Yesterday all my troubles seemed so far away. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>Nothing Else Matters</td>\n",
       "      <td>So close no matter how far Couldn't be much mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>Enter Sandman</td>\n",
       "      <td>Say your prayers, little one Don't forget, my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>Master of Puppets</td>\n",
       "      <td>End of passion play, crumbling away I’m your s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>The Unforgiven</td>\n",
       "      <td>New blood joins this earth, And quickly he's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>Fade to Black</td>\n",
       "      <td>Life, it seems, will fade away Drifting furthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>One</td>\n",
       "      <td>I can’t remember anything Can’t tell if this i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Metallica</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Make his fight on the hill in the early day Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>The Real Slim Shady</td>\n",
       "      <td>May I have your attention please? May I have y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>Till I Collapse</td>\n",
       "      <td>'Cause sometimes you just feel tired, Feel wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>Lose Yourself</td>\n",
       "      <td>Look, if you had, one shot, or one opportunity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>Stan</td>\n",
       "      <td>My tea's gone cold I'm wondering why I got out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>My Name Is</td>\n",
       "      <td>Hi! My name is... (what?) My name is... (who?)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist                      song  \\\n",
       "0     Beatles                     Help!   \n",
       "1     Beatles            Ticket to Ride   \n",
       "2     Beatles         A Hard Days Night   \n",
       "3     Beatles          Cant Buy Me Love   \n",
       "4     Beatles             Eleanor Rigby   \n",
       "5     Beatles  I Want to Hold Your Hand   \n",
       "6     Beatles             She Loves You   \n",
       "7     Beatles                 Yesterday   \n",
       "8   Metallica      Nothing Else Matters   \n",
       "9   Metallica             Enter Sandman   \n",
       "10  Metallica         Master of Puppets   \n",
       "11  Metallica            The Unforgiven   \n",
       "12  Metallica             Fade to Black   \n",
       "13  Metallica                       One   \n",
       "14  Metallica   For Whom the Bell Tolls   \n",
       "15     Eminem       The Real Slim Shady   \n",
       "16     Eminem           Till I Collapse   \n",
       "17     Eminem             Lose Yourself   \n",
       "18     Eminem                      Stan   \n",
       "19     Eminem                My Name Is   \n",
       "\n",
       "                                               lyrics  \n",
       "0   (When) When I was younger (When I was young) s...  \n",
       "1   I think I'm gonna be sad, I think it's today, ...  \n",
       "2   It's been a hard day's night, and I been worki...  \n",
       "3   Can't buy me love, love Can't buy me love I'll...  \n",
       "4   Ah look at all the lonely people Ah look at al...  \n",
       "5   Oh yeah, I'll tell you something I think you'l...  \n",
       "6   She loves you, yeah, yeah, yeah She loves you,...  \n",
       "7   Yesterday all my troubles seemed so far away. ...  \n",
       "8   So close no matter how far Couldn't be much mo...  \n",
       "9   Say your prayers, little one Don't forget, my ...  \n",
       "10  End of passion play, crumbling away I’m your s...  \n",
       "11  New blood joins this earth, And quickly he's s...  \n",
       "12  Life, it seems, will fade away Drifting furthe...  \n",
       "13  I can’t remember anything Can’t tell if this i...  \n",
       "14  Make his fight on the hill in the early day Co...  \n",
       "15  May I have your attention please? May I have y...  \n",
       "16  'Cause sometimes you just feel tired, Feel wea...  \n",
       "17  Look, if you had, one shot, or one opportunity...  \n",
       "18  My tea's gone cold I'm wondering why I got out...  \n",
       "19  Hi! My name is... (what?) My name is... (who?)...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('lyrics.txt', sep='\\t')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Terminology</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DataFrame - think Excel spreadsheet\n",
    "\n",
    "* Document - a single string of text information\n",
    "\n",
    "* Corpus - a collection of documents\n",
    "\n",
    "* Token - a word, phrase or symbol derived from a document\n",
    "\n",
    "* Tokenizer - function to split a document into a list of tokens\n",
    "\n",
    "* Document-Term Matrix - A matrix where rows are Documents and columns are Terms and values are counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Train a model to guess which artist wrote song based on lyrics\n",
    "\n",
    "* Count Model (Bag of Words)\n",
    "* TF-IDF Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and toy examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example corpus\n",
    "messages = [\"Hey hey hey lets go get lunch today :)\",\n",
    "           \"Did you go home?\",\n",
    "           \"Hey!!! I need a favor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey hey hey lets go get lunch today :)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example document\n",
    "document = messages[0]\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey', 'hey', 'hey', 'lets', 'go', 'get', 'lunch', 'today', ':)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tokens\n",
    "document.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count (Bag of Words) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* need a numerical representation for our corpus\n",
    "* will use CountVectorizer() from sci-kit learn library\n",
    "* creates matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* next we will use fit() and transform() methods\n",
    "* similar to fit() and predict() used in ML classifiers\n",
    "\n",
    "## Going to fit model on all documents at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['did', 'favor', 'get', 'go', 'hey', 'home', 'lets', 'lunch', 'need', 'today', 'you']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Number of tokens: 11'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before transforming look at feature names (columns names)\n",
    "print(vect.get_feature_names())\n",
    "'Number of tokens: {}'.format(len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "* all lowercase\n",
    "* words less than two letters are excluded\n",
    "* punctuation removed\n",
    "* no duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we'll use the transform() method to create a document term matrix (DTM). \n",
    "\n",
    "### This is the matrix of token counts we want to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.transform(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
       "0    0      0    1   1    3     0     1      1     0      1    0\n",
       "1    1      0    0   1    0     1     0      0     0      0    1\n",
       "2    0      1    0   0    1     0     0      0     1      0    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at it as a Matrix\n",
    "pd.DataFrame(dtm.toarray()\n",
    "             , columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there's lots of zeros in there, so they store it differently\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t3\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "print(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because each document has a column for every word that occurs in the corpus, DTM is predominatly filled with 0's\n",
    "* Sparse format can store the DTM in a smaller amount of memory and can speed up operations\n",
    "* a DTM of a large corpus can quickly balloon in size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get total counts for corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "did      1\n",
       "favor    1\n",
       "get      1\n",
       "go       2\n",
       "hey      4\n",
       "home     1\n",
       "lets     1\n",
       "lunch    1\n",
       "need     1\n",
       "today    1\n",
       "you      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if we get a new message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
       "0    0      0    1   1    1     0     1      0     0      0    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_message = ['Hey lets go get a drink tonight']\n",
    "new_dtm = vect.transform(new_message)\n",
    "pd.DataFrame(new_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* only tokens from original fit appear as features(columns)\n",
    "* need to refit with new message included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey hey hey lets go get lunch today :)',\n",
       " 'Did you go home?',\n",
       " 'Hey!!! I need a favor',\n",
       " 'Hey lets go get a drink tonight']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(new_message[0])\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>drink</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  drink  favor  get  go  hey  home  lets  lunch  need  today  tonight  \\\n",
       "0    0      0      0    1   1    3     0     1      1     0      1        0   \n",
       "1    1      0      0    0   1    0     1     0      0     0      0        0   \n",
       "2    0      0      1    0   0    1     0     0      0     1      0        0   \n",
       "3    0      1      0    1   1    1     0     1      0     0      0        1   \n",
       "\n",
       "   you  \n",
       "0    0  \n",
       "1    1  \n",
       "2    0  \n",
       "3    0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = vect.fit_transform(messages)\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we use CountVectorizer, this is what we get\n",
    "![title](countvect.png)\n",
    "\n",
    "### Can you think of a linguistics reason why we don't see much separation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Model: \n",
    "### - Not all Counts are the same\n",
    "### - Words unique to that document stand out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* term frequency inverse document frequency\n",
    "* generally more popular than bag of words model\n",
    "* numerical statistic to show how important an token is to a document\n",
    "* TF-IDF = term frequency * (1 / document frequency)\n",
    "* TF - how frequent a term(token) occurs in a document\n",
    "* IDF - inverse of how frequent a term occurs across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def createDTM(messages, tfidf=True):\n",
    "    if tfidf:\n",
    "        vect = TfidfVectorizer()\n",
    "    else:\n",
    "        vect = CountVectorizer()\n",
    "    dtm = vect.fit_transform(messages)\n",
    "    # create pandas dataframe of DTM\n",
    "    return pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF\n",
      "      favor       get       hey      lets     lunch      need\n",
      "0  0.000000  0.534046  0.379978  0.534046  0.534046  0.000000\n",
      "1  0.631667  0.000000  0.449436  0.000000  0.000000  0.631667\n",
      "Count\n",
      "   favor  get  hey  lets  lunch  need\n",
      "0      0    1    1     1      1     0\n",
      "1      1    0    1     0      0     1\n"
     ]
    }
   ],
   "source": [
    "messages = [\"Hey lets get lunch :)\",\n",
    "           \"Hey!!! I need a favor\"]\n",
    "print('TFIDF', createDTM(messages), sep='\\n')\n",
    "\n",
    "print('Count', createDTM(messages, False), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `'hey'` has lowest value, only word that occurs in both documents\n",
    "* `'favor'` and `'need'` have highest, occur in 1 document with fewest tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>hey</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363788</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.363788</td>\n",
       "      <td>0.363788</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      favor       get       hey      lets     lunch      need\n",
       "0  0.000000  0.363788  0.776515  0.363788  0.363788  0.000000\n",
       "1  0.631667  0.000000  0.449436  0.000000  0.000000  0.631667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add repeats of 'hey' to first message\n",
    "messages = [\"Hey hey hey lets get lunch :)\",\n",
    "           \"Hey!!! I need a favor\"]\n",
    "createDTM(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF for `'hey'` in first increases, but IDF for `'hey'` remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>hey</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      favor       get       hey      lets     lunch      need\n",
       "0  0.000000  0.288675  0.866025  0.288675  0.288675  0.000000\n",
       "1  0.707107  0.000000  0.000000  0.000000  0.000000  0.707107"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'hey' from second message\n",
    "messages = [\"Hey hey hey lets get lunch :)\",\n",
    "           \"I need a favor\"]\n",
    "createDTM(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `'hey'` for first message is now the highest value\n",
    "* `'favor'` and `'need'` also increase as there are now fewer tokens in the second message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing and Hyperparameters</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* max_features = n : only considers the top n words when ordered by term frequency\n",
    "* min_df = n : ignores words with a document frequency below n\n",
    "* max_df = n : ignores words with a document frequency above n\n",
    "* stop_words = [''] : ignores common words like `'the'`, `'that'`, `'which'` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_vect = TfidfVectorizer(stop_words='english',max_df=0.7)\n",
    "song_dtm = song_vect.fit_transform(df['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32x1983 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to plot this?   \n",
    "* we can't plot 1984 dimensions in an effective way\n",
    "* need to reduce dimensionality to 2 dimensions \n",
    "\n",
    "## Principle Component Analysis (PCA)\n",
    "* summarizes data using smaller number of dimensions\n",
    "* trys to retain variance and 'structure' of the data\n",
    "* a method for compressing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principle Component Analysis (PCA) to reduce down to two dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "X_pca = PCA(n_components=2).fit_transform(song_dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Help!</td>\n",
       "      <td>(When) When I was younger (When I was young) s...</td>\n",
       "      <td>-0.135698</td>\n",
       "      <td>0.066266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Ticket to Ride</td>\n",
       "      <td>I think I'm gonna be sad, I think it's today, ...</td>\n",
       "      <td>0.112914</td>\n",
       "      <td>-0.293119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>A Hard Days Night</td>\n",
       "      <td>It's been a hard day's night, and I been worki...</td>\n",
       "      <td>0.030226</td>\n",
       "      <td>-0.205211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Cant Buy Me Love</td>\n",
       "      <td>Can't buy me love, love Can't buy me love I'll...</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.334199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beatles</td>\n",
       "      <td>Eleanor Rigby</td>\n",
       "      <td>Ah look at all the lonely people Ah look at al...</td>\n",
       "      <td>-0.309337</td>\n",
       "      <td>0.063733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist               song  \\\n",
       "0  Beatles              Help!   \n",
       "1  Beatles     Ticket to Ride   \n",
       "2  Beatles  A Hard Days Night   \n",
       "3  Beatles   Cant Buy Me Love   \n",
       "4  Beatles      Eleanor Rigby   \n",
       "\n",
       "                                              lyrics         A         B  \n",
       "0  (When) When I was younger (When I was young) s... -0.135698  0.066266  \n",
       "1  I think I'm gonna be sad, I think it's today, ...  0.112914 -0.293119  \n",
       "2  It's been a hard day's night, and I been worki...  0.030226 -0.205211  \n",
       "3  Can't buy me love, love Can't buy me love I'll...  0.070407 -0.334199  \n",
       "4  Ah look at all the lonely people Ah look at al... -0.309337  0.063733  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A'] = X_pca[:,0]\n",
    "df['B'] = X_pca[:,1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 447.25x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.lmplot(x='A', y='B', data=df,fit_reg=False, hue='artist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinguishing musicians may low-stakes\n",
    "\n",
    "# But what if now you needed to find a suicide emails?\n",
    "![title](lives_saved.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----\n",
    "\n",
    "\n",
    "\n",
    "# Extra stuff on Linguistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* n-gram is a sequence of n words\n",
    "* bag of words model is actually a specific case of the N-gram model where n=1\n",
    "* Consider the string `'Buffalo Data Science Meetup'`\n",
    " * n=1 (unigram) :  `'Buffalo'`,`'Data'`,`'Science'`,`'Meetup'`  (Bag of words model)\n",
    " * n=2 (bigram) : `'Buffalo Data'`, `'Data Science'`, `'Science Meetup'`\n",
    " * n=3 (trigram) : `'Buffalo Data Science'`,`'Data Science Meetup`'\n",
    "* using n-gram model info about order of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = [\"Hey hey hey lets go get lunch today :)\",\n",
    "           \"Hey!!! I need a favor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get lunch</th>\n",
       "      <th>go get</th>\n",
       "      <th>hey hey</th>\n",
       "      <th>hey lets</th>\n",
       "      <th>hey need</th>\n",
       "      <th>lets go</th>\n",
       "      <th>lunch today</th>\n",
       "      <th>need favor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   get lunch  go get  hey hey  hey lets  hey need  lets go  lunch today  \\\n",
       "0          1       1        2         1         0        1            1   \n",
       "1          0       0        0         0         1        0            0   \n",
       "\n",
       "   need favor  \n",
       "0           0  \n",
       "1           1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at bigrams\n",
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "dtm = vect.fit_transform(messages)\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get lunch today</th>\n",
       "      <th>go get lunch</th>\n",
       "      <th>hey hey hey</th>\n",
       "      <th>hey hey lets</th>\n",
       "      <th>hey lets go</th>\n",
       "      <th>hey need favor</th>\n",
       "      <th>lets go get</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   get lunch today  go get lunch  hey hey hey  hey hey lets  hey lets go  \\\n",
       "0                1             1            1             1            1   \n",
       "1                0             0            0             0            0   \n",
       "\n",
       "   hey need favor  lets go get  \n",
       "0               0            1  \n",
       "1               1            0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at trigrams\n",
    "vect = CountVectorizer(ngram_range=(3,3))\n",
    "dtm = vect.fit_transform(messages)\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>get lunch</th>\n",
       "      <th>get lunch today</th>\n",
       "      <th>go</th>\n",
       "      <th>go get</th>\n",
       "      <th>go get lunch</th>\n",
       "      <th>hey</th>\n",
       "      <th>hey hey</th>\n",
       "      <th>hey hey hey</th>\n",
       "      <th>...</th>\n",
       "      <th>hey need</th>\n",
       "      <th>hey need favor</th>\n",
       "      <th>lets</th>\n",
       "      <th>lets go</th>\n",
       "      <th>lets go get</th>\n",
       "      <th>lunch</th>\n",
       "      <th>lunch today</th>\n",
       "      <th>need</th>\n",
       "      <th>need favor</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   favor  get  get lunch  get lunch today  go  go get  go get lunch  hey  \\\n",
       "0      0    1          1                1   1       1             1    3   \n",
       "1      1    0          0                0   0       0             0    1   \n",
       "\n",
       "   hey hey  hey hey hey  ...    hey need  hey need favor  lets  lets go  \\\n",
       "0        2            1  ...           0               0     1        1   \n",
       "1        0            0  ...           1               1     0        0   \n",
       "\n",
       "   lets go get  lunch  lunch today  need  need favor  today  \n",
       "0            1      1            1     0           0      1  \n",
       "1            0      0            0     1           1      0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at unigrams, bigrams, and trigrams\n",
    "vect = CountVectorizer(ngram_range=(1,3))\n",
    "dtm = vect.fit_transform(messages)\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get lunch</th>\n",
       "      <th>go get</th>\n",
       "      <th>hey hey</th>\n",
       "      <th>hey lets</th>\n",
       "      <th>hey need</th>\n",
       "      <th>lets go</th>\n",
       "      <th>lunch today</th>\n",
       "      <th>need favor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   get lunch    go get   hey hey  hey lets  hey need   lets go  lunch today  \\\n",
       "0   0.333333  0.333333  0.666667  0.333333  0.000000  0.333333     0.333333   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.707107  0.000000     0.000000   \n",
       "\n",
       "   need favor  \n",
       "0    0.000000  \n",
       "1    0.707107  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use with tf-idf\n",
    "vect = TfidfVectorizer(ngram_range=(2,2))\n",
    "dtm = vect.fit_transform(messages)\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'much', 'found', 'her', 'they', 'too', 'only', 'on', 'get', 'out', 'along', 'such', 'then', 'keep', 'formerly', 'through', 'thereby', 'had', 'which', 'all', 'etc', 'again', 'until', 'beside', 'full', 'cant', 'own', 'them', 'empty', 'will', 'in', 'be', 'is', 'further', 'go', 'elsewhere', 'indeed', 'most', 'would', 'herself', 'everywhere', 'below', 'thence', 'five', 'me', 'since', 'am', 'nowhere', 'few', 'alone', 'back', 'take', 'up', 'whoever', 'else', 'whereafter', 'hers', 'less', 'for', 'whence', 'besides', 'none', 'something', 'twenty', 'amongst', 'at', 'during', 'many', 'nine', 'hence', 'have', 'can', 'between', 'itself', 'least', 'someone', 'whatever', 'de', 'yourself', 'eleven', 'its', 'off', 'system', 'put', 'after', 'noone', 'some', 'hereby', 'this', 'thereupon', 'no', 'there', 'because', 'seemed', 'themselves', 'beforehand', 'forty', 'though', 'could', 'very', 'another', 'call', 'whereupon', 'whose', 'couldnt', 'now', 'ie', 'myself', 'amount', 'done', 'fill', 'how', 'always', 'everyone', 'thick', 'together', 'mine', 'toward', 'upon', 'fifteen', 'thru', 'whereas', 'side', 'fire', 'often', 'hereupon', 'down', 'whom', 'thin', 'became', 'not', 'ourselves', 'so', 'neither', 'however', 'where', 'seems', 'whither', 'across', 'four', 'afterwards', 'any', 'towards', 'an', 'seeming', 'onto', 'give', 'one', 'describe', 'mill', 'been', 'due', 'three', 're', 'twelve', 'what', 'whether', 'sometime', 'co', 'part', 'wherever', 'around', 'namely', 'yourselves', 'might', 'it', 'behind', 'inc', 'somewhere', 'un', 'was', 'above', 'interest', 'we', 'who', 'may', 'ten', 'my', 'sincere', 'rather', 'bill', 'by', 'your', 'please', 'hundred', 'well', 'than', 'never', 'anyhow', 'same', 'these', 'he', 'sixty', 'him', 'with', 'nothing', 'why', 'yours', 'among', 'and', 'wherein', 'latterly', 'fifty', 'already', 'via', 'last', 'against', 'hasnt', 'next', 'his', 'see', 'also', 'hereafter', 'nevertheless', 'should', 'six', 'a', 'being', 'seem', 'each', 'into', 'show', 'or', 'somehow', 'thereafter', 'former', 'per', 'even', 'front', 'cry', 'throughout', 'do', 'two', 'our', 'eg', 'still', 'every', 'ours', 'i', 'several', 'himself', 'perhaps', 'whereby', 'detail', 'everything', 'that', 'anything', 'here', 'their', 'eight', 'either', 'cannot', 'sometimes', 'made', 'top', 'name', 'were', 'beyond', 'while', 'ever', 'meanwhile', 'amoungst', 'whole', 'almost', 'once', 'from', 'nor', 'other', 'are', 'the', 'anywhere', 'except', 'therein', 'although', 'herein', 'become', 'therefore', 'anyone', 'more', 'thus', 'first', 'when', 'enough', 'you', 'but', 'without', 'both', 'if', 'must', 'to', 'us', 'about', 'move', 'of', 'bottom', 'as', 'con', 'latter', 'she', 'becomes', 'those', 'whenever', 'serious', 'yet', 'nobody', 'ltd', 'moreover', 'under', 'find', 'over', 'others', 'anyway', 'within', 'becoming', 'has', 'third', 'otherwise', 'before', 'mostly'})\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "print(vect.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'cedarville', 'linguistics', 'python'})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining our own stopwords\n",
    "my_words = ['cedarville','linguistics','python']\n",
    "vect = CountVectorizer(stop_words=my_words)\n",
    "vect.get_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Stemming\n",
    "* reduces a word down to its base/root form\n",
    "* crude heuristic that works by chopping off end of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "tokens = ['linguistics','linguist','lingua']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linguist', 'linguist', 'lingua']\n"
     ]
    }
   ],
   "source": [
    "stems = [stemmer.stem(i) for i in tokens]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Lemmatization\n",
    "* similar to stemming\n",
    "* seeks to find base dictionary form\n",
    "* more complex, may need to specify part of speech for accurate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "lemmer = WordNetLemmatizer()\n",
    "tokens = ['hands','women']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hand', 'woman']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = [lemmer.lemmatize(i) for i in tokens]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manufacturing'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmer.lemmatize('manufacturing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manufacture'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify it as a verb, default is noun\n",
    "lemmer.lemmatize('manufacturing','v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
